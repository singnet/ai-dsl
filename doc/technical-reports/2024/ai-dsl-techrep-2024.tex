%% Technical Report for the work on the AI-DSL over 2024

\documentclass[]{report}
\usepackage{url}
\usepackage{minted}
\usepackage[textsize=footnotesize]{todonotes}
\newcommand{\kabir}[2][]{\todo[color=yellow,author=kabir, #1]{#2}}
\newcommand{\nil}[2][]{\todo[color=purple,author=nil, #1]{#2}}
\usepackage[hyperindex,breaklinks]{hyperref}
\usepackage{breakurl}
\usepackage{listings}
\lstset{basicstyle=\ttfamily\footnotesize,breaklines=false,frame=single}
\usepackage{float}
\restylefloat{table}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage[skip=0pt]{subcaption}
\usepackage{circledsteps}

\begin{document}

\title{AI-DSL Technical Report 2024}
\author{Nil Geisweiller}
\maketitle

\begin{abstract}
\end{abstract}

\tableofcontents

\chapter{Introduction}

During the middle of 2023 it became apparent that MeTTa~\cite{MeTTa}
could soon be used instead of Idris~\cite{Idris} for program
synthesis.  Around the end of 2023 a general purpose
chainer~\cite{Chaining} was developed and improved throughout 2024 and
we thus began experimenting with it to synthesize AI service
compositions.  In this document we will go over the work that was done
in order to accomplished such a feat.  It can be summarized as
follows:
\begin{itemize}
\item Develop and improve a general purpose chainer in MeTTa
  supporting backward, forward and in fact \emph{omniward} chaining
  and can handle dependent types.
\item Develop a SingularityNET Market Place crawler to gather
  information about AI services and convert that information into
  MeTTa specifications.
\item Extensively experiment with AI service composition using the
  aforementioned chainer.  Various AI service composition
  representations (including lambda abstraction and combinatory logic)
  were explored, as well as the tractability of the corresponding
  synthesis processes.
\item Prototype an AI-DSL ontology in MeTTa.
\item Implement a MeTTa to DOT converter to graphically display
  synthesized AI service compositions.
\end{itemize}
At the end of this process we finally managed to efficiently
synthesize the English to Chinese Song test case described
in~\cite{AIDSLService2023} (an add-on to the technical report of
2022~\cite{AIDSLReport2022}).  By itself this is of course very
promising.  It should be mentioned though that, in order to make the
synthesis tractable, only the services involved in that composition
were considered in the knowledge base fed to the chainer.  Attempting
to perform such synthesis while considering all available AI services
will be the subject of the next round of work on the AI-DSL.

\chapter{Program Synthesis in MeTTa}

In this chapter I will explain how program synthesis can be done in
MeTTa and go over the various backward chainers I have prototyped
during 2023 and 2024.  This will come handy for
Chapter~\ref{chap:xpaicompo} which goes over a number of experiments
on AI service compositions based on these chainers.  Why backward
chaining, you may ask?  Because it allows to go from theorems to
axioms.  In the context of AI service composition, a theorem would be
the formal specification of an overall AI service composition, such
as\\

\emph{Turn any English song into a corresponding Chinese one}\\[0.4cm]
and the axioms would be the formal specification of every AI service
involved in the composition, such as
\begin{itemize}
\item \emph{Convert speech to text.}
\item \emph{Translate English to Chinese.}
\item \emph{Turn Audio into MIDI.}
\item $\dots$
\end{itemize}
Then the backward chainer would take the overall specification and
combine existing AI services to fulfill it altogether.  Going forward
could be useful as well but for a different type of queries, such as\\

\emph{Given all these AI services, what can you come up with by
combining them?}\\[0.4cm] and the forward chainer would combine them
to form random, albeit valid, compositions and provide their formal
specifications.  Then there is everything between forward and backward
chaining, what I call \emph{omni} chaining.  For instance, the query
could provide an incomplete specification of the overall composition,
alongside some AI services which should be involved, and let the omni
chainer come up with completions of such specifications using the
provided AI services.  My prototypes cover all of these possibilities,
but in this report I will only focus on backward chaining because that
is what I exclusively used for the AI-DSL work so far.
\section{Curried Backward Chainer}
\label{sec:curriedbc}

Let us begin with the Curried Backward Chainer, the simplest of them
all.  The curried backward chainer is simple because it assumes that
there is only one way to construct terms, using unary function
application.  In this case a term can be either
\begin{itemize}
\item a constant,
\item or a term applied to a term.
\end{itemize}
A constant could represent a value such as \mintinline{scheme}{42}, or
a function like a standalone AI service such as
\mintinline{scheme}{speech2text}.  In an application, the first term
must correspond to a unary function, such as \mintinline{scheme}{foo},
and the second term must correspond to its argument, such as
\mintinline{scheme}{42}, resulting in an application such as
\mintinline{scheme}{(foo 42)}.  Emulating n-ary application can be
done by considering higher order unary functions.  For instance
\mintinline{scheme}{(+ 1 2)} can be represented in curried format by
\mintinline{scheme}{((+ 1) 2)}.  Contrary to most functional
programming languages, currying is not handled automatically in MeTTa,
thus a non-curried version of \mintinline{scheme}{+} would be typed
\begin{minted}{scheme}
  (-> Number Number Number)
\end{minted}
while a curried version would be typed
\begin{minted}{scheme}
  (-> Number (-> Number Number))
\end{minted}
In the curried backward chainer, all functions are assumed to be unary
and that is how currying is handled.  As per the Curry-Howard
correspondence, functions on the programming side correspond to
inference rules on the logical side, so our curried backward chainer
can also handle synthesizing proofs, not just programs.  The AI-DSL
actually uses both sides at the same time producing AI service
compositions containing programs and proofs.  Why on earth would we
want that is explained in detail in Chapter~\ref{chap:xpaicompo}.\\

The MeTTa implementation of the curried backward chainer can be found
in~\cite{CurriedBackwardChainer} is given in full below\pagebreak
\begin{minted}{scheme}
;; Curried Backward Chainer type signature
(: bc (-> $a                            ; Knowledge base space
          Nat                           ; Maximum depth
          $b                            ; Query
          $b))                          ; Result

;; Base case
(= (bc $kb $_ (: $prf $thrm))
   (match $kb (: $prf $thrm) (: $prf $thrm)))

;; Recursive step
;; Unary proof application
(= (bc $kb (S $k) (: ($prfabs $prfarg) $thrm))
   (let* (;; Recursive call on function
          ((: $prfabs (-> $prms $thrm))
           (bc $kb $k (: $prfabs (-> $prms $thrm))))
          ;; Recursive call on argument
          ((: $prfarg $prms)
           (bc $kb $k (: $prfarg $prms))))
     ;; Query with holes filled
     (: ($prfabs $prfarg) $thrm)))
\end{minted}
Let us walk over that code.
\begin{enumerate}
\item The type signature takes
  \begin{itemize}
  \item A knowledge base containing the axioms, which can in fact be
    viewed as the rewrite rules as well.  In a way the knowledge base
    contains the description of the logic the backward chainer is
    going to operate on.
  \item A maximum depth corresponding to the maximum depth of the
    syntax tree that the backward chainer is allowed to produce.
  \item A query of the form
    \begin{minted}{scheme}
      (: TERM TYPE)
    \end{minted}
    indicating that \mintinline{scheme}{TERM} is of type
    \mintinline{scheme}{TYPE}.  The query may contains free variables
    representing holes that the backward chainer must fill.  For
    instance if the query is
    \begin{minted}{scheme}
      (: $prg (-> Number String))
    \end{minted}
    there is one big hole, \mintinline{scheme}{$prg}, in place of the
    term, indicating that the backward chainer must find a program
    with the type signature
    \begin{minted}{scheme}
      (-> Number String)
    \end{minted}
    The same backward chainer can be used to infer a type if the hole is
    placed on type.  For instance the query
    \begin{minted}{scheme}
      (: (foo 42) $type)
    \end{minted}
    indicates that the backward chainer must infer the type of
    \mintinline{scheme}{(foo 42)}.  Holes can be placed anywhere and
    at any depth across the term and the type of the query, such as
    \begin{minted}{scheme}
      (: (+ $val) (-> $input Number))
    \end{minted}
    and the backward chainer must attempt to fill the holes
    regardless.  Each result returned will be the query itself with
    the holes filled.  If more than one result exists then the
    backward chainer will return a superposition of results.
  \end{itemize}
\item The base case
  \begin{minted}{scheme}
    (match $kb (: $prf $thrm) (: $prf $thrm)))
  \end{minted}
  is simply a match query over the knowledge base. If the query is an
  axiom, then it returns it.  If it matches several axioms, then it
  returns a superposition of all matches.
\item The recursive step occurs if the query is of the form
  \begin{minted}{scheme}
    (: ($prfabs $prfarg) $thrm)
  \end{minted}
  corresponding to a unary application, and the depth is greater than
  zero, enforced by having to match the depth argument
  \mintinline{scheme}{(S $k)}.  If the backward chainer enters that
  call, then it breaks up the query into two subqueries:
  \begin{enumerate}
  \item one to discover \mintinline{scheme}{$prfabs}, the function,
  \item the other to discover \mintinline{scheme}{$prfarg}, the
    argument.
  \end{enumerate}
  \mintinline{scheme}{$prfabs} stands for \emph{proof abstraction},
  reflecting the idea that it is a function that takes a proof in
  input and outputs a proof, merely corresponding to a regular
  function on the programming side of the Curry-Howard isomorphism.
  And \mintinline{scheme}{$prfarg} stands for \emph{proof argument},
  reflecting the idea that it is an argument provided to a proof
  abstraction.  On the logical side of the Curry-Howard
  correspondence, you can roughly think of
  \mintinline{scheme}{$prfabs} as being an inference rule, while
  \mintinline{scheme}{$prfarg} being the proof of a premise of that
  inference rule.  I say roughly because \mintinline{scheme}{$prfabs}
  may not just be an inference rule, it can be more general than that,
  a proof function that takes in input a proof and outputs a proof, or
  \emph{proof abstraction} as I like to say, which you can think as a
  composite inference rule.  The broken up query to discover the
  function is
  \begin{minted}{scheme}
    (bc $kb $k (: $prfabs (-> $prms $thrm)))
  \end{minted}
  ordering the backward chainer to look for a proof abstraction that,
  if given a proof of a premise, \mintinline{scheme}{$prms}, to be
  discovered as well, then it outputs a proof of
  \mintinline{scheme}{$thrm}, the conclusion.  The broken up query to
  discover the argument is
  \begin{minted}{scheme}
    (bc $kb $k (: $prfarg $prms))
  \end{minted}
  ordering the backward chainer to look for a proof of the premise
  \mintinline{scheme}{$prms}.
\end{enumerate}
One may notice that, unlike function definitions in regular functional
programming languages, the base case is not constrained by its depth.
In the base case of this MeTTa program, \mintinline{scheme}{$_} does
not mean \emph{otherwise}, it means \emph{any time}.  The
non-determinism of MeTTa allows both the base case and the recursive
step to be taken simultaneously.  The resulting effect is that a call
of \mintinline{scheme}{bc} can bottom down at any depth up to the
maximum depth, producing proof trees of any size up to the maximum
depth.  Let us now provide an example.  First, let us fill the
knowledge with a theory
\begin{minted}{scheme}
;; Knowledge base
!(bind! &kb (new-space))
!(add-atom &kb (: 42 Number))
!(add-atom &kb (: foo (-> Number String)))
!(add-atom &kb (: bar (-> String Bool)))
!(add-atom &kb (: . (-> (-> $b $c) (-> (-> $a $b) (-> $a $c)))))
\end{minted}
That theory expresses that \mintinline{scheme}{42} is a number,
provides two casting functions, one from \mintinline{scheme}{Number}
to \mintinline{scheme}{String}, called \mintinline{scheme}{foo}, and
the other one from \mintinline{scheme}{String} to
\mintinline{scheme}{Bool}, called \mintinline{scheme}{bar}.  Finally,
it provides a higher order composition operator \mintinline{scheme}{.}
also called the \emph{Bluebird} combinator in~\cite{TODO}.  Given that
theory we can now call the backward chainer with a few queries.  For
starter, let us infer the type of 42.
\begin{minted}{scheme}
;; Infer the type of 42
!(bc &kb Z (: 42 $type))
\end{minted}
which outputs
\begin{minted}{scheme}
[(: 42 Number)]
\end{minted}
Next, let us synthesize terms of type \mintinline{scheme}{String}
\begin{minted}{scheme}
;; Synthesize terms of type String
!(bc &kb (S Z) (: $prg String))
\end{minted}
which outputs
\begin{minted}{scheme}
[(: (foo 42) String)]
\end{minted}
The depth for this query must be at least 1, represented by
\mintinline{scheme}{(S Z)} as \mintinline{scheme}{Nat}, because the
term to be synthesized is a function application requiring to enter
the recursive step of \mintinline{scheme}{bc} at least once.  Finally,
let us synthesize all unary functions that outputs a Boolean value.
\begin{minted}{scheme}
;; Synthesize all functions that output a Boolean value
!(bc &kb (S (S Z)) (: $prg (-> $intput Bool)))
\end{minted}
which outputs the superposition of two solutions
\begin{minted}{scheme}
[(: ((. bar) foo) (-> Number Bool)),
 (: bar (-> String Bool))]
\end{minted}
one turning a number into a Boolean value,
\mintinline{scheme}{((. bar) foo)}, the other one turning a string
into a Boolean value, \mintinline{scheme}{bar}.\\

To help you understand what is going I have printed the trace of the
\mintinline{scheme}{bc} call of the last query.
\mintinline{scheme}{bc-bas} corresponds to the base case entry,
\mintinline{scheme}{bc-rec} corresponds to the recursive step entry.
The knowledge base argument is missing from the trace to be more
concise.  I have manually reconstructed the tree representing the
recursive calls and added some comments.  Note that the tree does not
show the distinction between non-determinism across branches and
regular functional evaluation along one branch.  I hope the trace
conveys what is going on in spite of that omission.  Obviously it
would be nice if MeTTa could offer a tool to automatically display
such trace and show such distinctions.\\
\begin{footnotesize}
\begin{minted}{scheme}
| ;; Original call, base case, succeeds (match bar)
|-(bc-bas (S (S Z)) (: $prg (-> $intput Bool)))
| ;; Original call, recursive step
|-(bc-rec (S (S Z)) (: ($prfabs#219 $prfarg#220) (-> $intput Bool)))
  | ;; First recursive call on function, base case, fails
  |-(bc-bas (S Z) (: $prfabs#219 (-> $prms#222 (-> $intput Bool))))
  | ;; First recursive call on function, recursive step
  |-(bc-rec (S Z) (: ($prfabs#730 $prfarg#731) (-> $prms#222 (-> $intput Bool))))
  | | ;; Second recursive call on function, base case, succeeds (match .)
  | |-(bc-bas Z (: $prfabs#730 (-> $prms#733 (-> $prms#222 (-> $intput Bool)))))
  | | ;; Second recursive call on argument, base case, succeeds (match bar)
  | |-(bc-bas Z (: $prfarg#731 (-> $b#1364 Bool)))
  | ;; First recursive call on argument, base case, succeeds (match foo)
  |-(bc-bas (S Z) (: $prfarg#220 (-> $intput String)))
  | ;; First recursive call on argument, recursive step
  |-(bc-rec (S Z) (: ($prfabs#2202 $prfarg#2203) (-> $intput String)))
    | ;; Second recursive call on function, base case, fails
    |-(bc-bas Z (: $prfabs#2202 (-> $prms#2205 (-> $intput String))))
\end{minted}
\end{footnotesize} Upon the second recursive call on function, entering the base case
\begin{small}
\begin{minted}{scheme}
(bc-bas Z (: $prfabs#730 (-> $prms#733 (-> $prms#222 (-> $intput Bool)))))
\end{minted}
\end{small} the successful match of the query against
\begin{small}
\begin{minted}{scheme}
(: . (-> (-> $b $c) (-> (-> $a $b) (-> $a $c))))
\end{minted}
\end{small}
creates bindings which are passed upstream to
the caller (the first recursive call on function).  As a result, by
the time the second recursive call on argument enters the base case
\begin{small}
\begin{minted}{scheme}
(bc-bas Z (: $prfarg#731 (-> $b#1364 Bool)))
\end{minted}
\end{small} the premise \mintinline{scheme}{$prms#733} has been substituted by
\mintinline{scheme}{(-> $b#1364 Bool)}.  This comes from
\mintinline{scheme}{(-> $b $c)} because \mintinline{scheme}{$c} was
unified with \mintinline{scheme}{Bool} while attempting to match
\mintinline{scheme}{(-> $intput Bool)} against
\mintinline{scheme}{(-> $a $c)}.\\

If at this point what is going on is still unclear, I recommend to run
the code, query by query, while tracing the function calls.  To that
end I have included a file~\cite{TODO}
\begin{minted}{bash}
  curry-backward-chainer-example.metta
\end{minted}
containing the code described above, wrapped in \texttt{trace!} calls.
As its name indicates \texttt{trace!} is a MeTTa primitive to trace
MeTTa code.

\section{Uncurried Backward Chainer}

It is not always convenient to manipulate curried expression, in that
case, extending the curried backward chainer to support more than
unary functions can be done by adding more entries in the backward
chainer definition.  Specifically, right below the unary proof
application recursive step
\begin{minted}{scheme}
;; Unary proof application
(= (bc $kb (S $k) (: ($prfabs $prfarg) $thrm))
   ...)
\end{minted}
one may simply add
\begin{minted}{scheme}
;; Binary proof application
(= (bc $kb (S $k) (: ($prfabs $prfarg1 $prfarg2) $thrm))
   (let* (;; Recursive call on function
          ((: $prfabs (-> $prms1 $prms2 $thrm))
           (bc $kb $k (: $prfabs (-> $prms1 $prms2 $thrm))))
          ;; Recursive call on first argument
          ((: $prfarg $prms1)
           (bc $kb $k (: $prfarg1 $prms1)))
          ;; Recursive call on second argument
          ((: $prfarg $prms2)
           (bc $kb $k (: $prfarg2 $prms2))))
     ;; Query with holes filled
     (: ($prfabs $prfarg1 $prfarg2) $thrm)))
\end{minted}
to support uncurried binary functions.  Or
\begin{minted}{scheme}
;; Ternary proof application
(= (bc $kb (S $k) (: ($prfabs $prfarg1 $prfarg2 $prfarg3) $thrm))
   (let* (;; Recursive call on function
          ((: $prfabs (-> $prms1 $prms2 $prms3 $thrm))
           (bc $kb $k (: $prfabs (-> $prms1 $prms2 $prms3 $thrm))))
          ;; Recursive call on first argument
          ((: $prfarg $prms1)
           (bc $kb $k (: $prfarg1 $prms1)))
          ;; Recursive call on second argument
          ((: $prfarg $prms2)
           (bc $kb $k (: $prfarg2 $prms2)))
          ;; Recursive call on third argument
          ((: $prfarg $prms3)
           (bc $kb $k (: $prfarg3 $prms3))))
     ;; Query with holes filled
     (: ($prfabs $prfarg1 $prfarg2 $prfarg3) $thrm)))
\end{minted}
to support uncurried ternary functions, etc.  One may write a MeTTa
macro (which is just a regular MeTTa program) to generate such code
for any given arity.  Although since the arities of the functions we
manipulate for reasoning are usually low, we have not found the need
to do that so far.

\section{Embed Inference Rules}

Another possible extension of the backward chainer is to embed its
axioms and inference rules directly in its code.  For instance the
theory given in example in Section~\ref{sec:curriedbc} we be directly
implemented as the following specialized backward chainer

\begin{minted}{scheme}
;; Base cases
(= (bc $_ (: 42 Number)) (: 42 Number))
(= (bc $_ (: foo (-> Number String))) (: foo (-> Number String)))
(= (bc $_ (: bar (-> String Bool))) (: bar (-> String Bool)))

;; Recursive step
;; Function composition
(= (bc (S $k) (: (. $prfarg1 $prfarg2) (-> $a $c)))
   (let* (;; Recursive call on first argument
          ((: $prfarg1 (-> $b $c))
           (bc $kb $k (: $prfarg1 (-> $b $c))))
          ;; Recursive call on second argument
          ((: $prfarg2 (-> $a $b))
           (bc $kb $k (: $prfarg2 (-> $a $b)))))
      (: (. $prfarg1 $prfarg2) (-> $a $c))))
\end{minted}
In this example the entire theory is embedded in the backward chainer
implementation, but one can also write a hybrid backward chainer with
some rules being generic, and some being embedded in the code.  One
advantage of embedding the theory directly in the backward chainer
implementation is that some axioms or rules can be given some special
treatments.  Examples of such implementations will be shown in
Chapter~\ref{TODO}.

\section{Dependent Types}

Simply explained, \emph{dependent types}~\cite{TODO} allow to use
values inside types.  An example of what can be done with dependent
types that is often given is a vector data structure where the size of
the vector is specified within the type itself.  Such definition may
in Idris look like
\begin{minted}{idris}
-- Vector type parameterized by element type and size
Vect : a -> Nat -> Type

-- Build a vector by repeating a given element n times
repeat : a -> (n : Nat) -> (Vect a n)
\end{minted}
Given that definition one may build the following
\begin{minted}{idris}
(repeat "abc" 42) : (Vect String 42)
\end{minted}
corresponding to a vector of 42 strings of \mintinline{idris}{"abc"}.
One can then pursue to write operators manipulating vectors allowing
consistency checking on their sizes to take place at compile time.
For instance \mintinline{idris}{append} would have the following type
signature
\begin{minted}{idris}
-- Append one vector of size n with another one of size m
append : (Vect a n) -> (Vect a m) -> (Vect a (n + m))
\end{minted}
Note that the vector size inside the output type is
\mintinline{idris}{(n + m)}.\\

As of today, dependent types are not supported by the built-in type
checker of MeTTa.  Luckily for us however, only a few modifications
need to be operated to have the backward chainer support dependent
types in MeTTa.

\subsection{Rule Format for Dependent Types}
\label{subsec:frmtdt}
First, the format of an inference rule must be changed from
\begin{minted}{scheme}
(-> PREMISE CONCLUSION)
\end{minted}
to
\begin{minted}{scheme}
(-> (: ARGUMENT PREMISE) CONCLUSION)
\end{minted}
where \mintinline{scheme}{ARGUMENT} would typically appear inside
\mintinline{scheme}{CONCLUSION}, the \emph{dependent} part of
dependent types.  An example of such inference rule would be
\begin{minted}{scheme}
(: translate
   (-> (: $src-lang NaturalLanguage) (: $dst-lang NaturalLanguage)
       (-> (: $_ (TextIn $src-lang)) (TextIn $dst-lang))))
\end{minted}
This inference rule represents an actually AI service from the
SingularityNET market place that translates a text in some source
language to an equivalent text in some destination language.  The
first two arguments of the type signature of the service are the
source and destination languages
\begin{minted}{scheme}
(: $src-lang NaturalLanguage)
(: $dst-lang NaturalLanguage)
\end{minted}
Because the argument terms, \mintinline{scheme}{$src-lang} and
\mintinline{scheme}{$dst-lang}, are specified in the type signature,
they can be passed as parameters to the other following types
\begin{minted}{scheme}
(TextIn $src-lang)
(TextIn $dst-lang)
\end{minted}
where \mintinline{scheme}{TextIn} is a parameterized type representing
a text in a given language.  One may notice the use of
\mintinline{scheme}{$_} representing a variable that is not
subsequently used to create dependencies\footnote{Please be aware that
in MeTTa \mintinline{scheme}{$_} is a regular variable and does behave
like an underscore in a functional programming language like Haskell.
Thus multiple occurrences of \mintinline{scheme}{$_} within the same
scope still will point to the same variable.}.  That is because in the
current format, unlike in Idris, specifying the argument associated to
the input of an arrow type is mandatory.  This may eventually become
optional to have more concise type signatures.  One may also notice
that the rule is a mixture of curried and uncurried arguments.  The
first two arguments are uncurried while the last one is curried.  This
is perfectly fine and comes from a convention that has been adopted in
some experiments, which is that arguments of AI services corresponding
to hyper-parameters are uncurried, while those corresponding to data
being processed are curried.  The reason for this convention is
explained in detail in Chapter~\ref{TODO}.

\subsection{Backward Chainer for Dependent Types}

With all that said, modifying the backward chainer to support
dependent types is as trivial as it may be.  The code is identical to
the backward chainers presented above but the queries must follow the
format presented in Subsection~\ref{subsec:frmtdt}.  The full
implementation for the modified curried backward chainer is given
below
\begin{minted}{scheme}
;; Dependently Typed Curried Backward Chainer type signature
(: bc (-> $a                            ; Knowledge base space
          Nat                           ; Maximum depth
          $b                            ; Query
          $b))                          ; Result

;; Base case
(= (bc $kb $_ (: $prf $thrm))
   (match $kb (: $prf $thrm) (: $prf $thrm)))

;; Recursive step
;; Unary proof application
(= (bc $kb (S $k) (: ($prfabs $prfarg) $thrm))
   (let* (;; Recursive call on function
          ((: $prfabs (-> (: $prfarg $prms) $thrm))
           (bc $kb $k (: $prfabs (-> (: $prfarg $prms) $thrm))))
          ;; Recursive call on argument
          ((: $prfarg $prms)
           (bc $kb $k (: $prfarg $prms))))
     ;; Query with holes filled
     (: ($prfabs $prfarg) $thrm)))
\end{minted}
Only two lines have changed, the query of the recursive call on
function has gone from
\begin{minted}{scheme}
(: $prfabs (-> $prms $thrm))
\end{minted}
to
\begin{minted}{scheme}
(: $prfabs (-> (: $prfarg $prms) $thrm))
\end{minted}
that is all.  An example of using such dependently typed backward
chainer to prove properties about programs can be found in~\ref{TODO}.
The chainer used for most of the AI-DSL experiments is based on it,
with the additional support for uncurried and embedded rules.  We are
almost done regarding chaining, but there is one last extension we
need to cover because some experiments were conducted with it, the
support for lambda abstraction.

\section{Lambda Abstraction}
In $\lambda$-calculus, lambda abstraction, or $\lambda$ abstraction,
is a way to construct functions.  On the proof side of the
Curry-Howard correspondence, $\lambda$ abstraction is a way to
construct proof functions, or what I like to call \emph{proof
abstractions}, a function that takes a proof in argument and outputs a
proof.  If the argument is the proof of a certain hypothesis $H$, and
the output is a proof of a conclusion $C$, then the proof abstraction
is a function that computes a way to go from a proof of $H$ to a proof
of $C$, which can be denoted with the arrow type as $H \to C$.
Function construction is the dual of function application.  Just like
function construction can be viewed as hypothesis introduction,
function application can be viewed as modus ponens.  That is, given a
body $c : C$, containing a free variable $x$ of type $H$, one can use
lambda abstraction to construct the following implication $$\lambda
x. c : H \to C$$ Likewise, applying such proof abstraction to proof $h
: H$, results in proof $$((\lambda x. c)\ h) : C$$ emulating the
behavior of the modus ponens inference rule.  Thus one may conclude
that the backward chainer presented so far is essentially a generic
implementation of modus ponens.  It makes sense therefore that one
would want to support its dual operation, lambda abstraction.

\chapter{Crawling the SingularityNET Market Place}

\chapter{Experimenting with AI Service Composition in MeTTa}
\label{chap:xpaicompo}

\section{AI-DSL Ontology}

\chapter{Conclusion}

\section{Acknowledgments}

Thanks to Matt Ikle and Khellar Crawford for our numerous discussions.
Thanks to Remy Clarke for mentioning APL and BQN.  Thanks to Douglas
Miles and his team for making MeTTaLog without which that work would
not have been possible.

%% \appendix
%% \chapter{Glossary}

\bibliographystyle{splncs04} \bibliography{local}

\end{document}
